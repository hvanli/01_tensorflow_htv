{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2d1e9d-8962-4876-aa61-26ea991d7bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNice, youâ€™ve now got a best model from Keras Tuner ğŸ¯\\nFrom here there are **two big levers**:\\n\\n1. **Make the model itself better** (architecture, regularization, hyperparams)\\n2. **Make the *data & training* setup better** (features, targets, training schedule)\\n\\nIâ€™ll give you concrete things you can do *right now* with code.\\n\\n---\\n\\n## 1. Fine-tune your current best model\\n\\nYou already have `best_model` and `best_hp`. Easiest improvement:\\n**keep training the same model with a smaller learning rate.**\\n\\n```python\\n# Take the tuned model\\nbest_model = tuner.hypermodel.build(best_hp)\\n\\n# Optionally re-train from scratch with tuned hp\\nhistory = best_model.fit(\\n    X_train_normal,\\n    y_train,\\n    validation_data=(X_test_normal, y_test),\\n    epochs=100,\\n    callbacks=callbacks,\\n    verbose=0\\n)\\n\\n# Now fine-tune with smaller lr\\nimport keras\\n\\nold_lr = best_hp.get(\"learning_rate\")\\nfine_tune_lr = old_lr * 0.1\\n\\nbest_model.compile(\\n    loss=\"mae\",\\n    optimizer=keras.optimizers.Adam(learning_rate=fine_tune_lr),\\n    metrics=[\"mae\", \"mse\"]\\n)\\n\\nhistory_ft = best_model.fit(\\n    X_train_normal,\\n    y_train,\\n    validation_data=(X_test_normal, y_test),\\n    epochs=50,\\n    callbacks=callbacks,\\n    verbose=0\\n)\\n\\nbest_model.evaluate(X_test_normal, y_test)\\n```\\n\\nThis alone can squeeze a bit more performance by â€œpolishingâ€ weights.\\n\\n---\\n\\n## 2. Add regularization (dropout / L2) and tune it\\n\\nRight now your model is:\\n\\n* Dense â†’ Dense â†’ Dense(1)\\n\\nYou can improve **generalization** by:\\n\\n* Adding **L2 weight decay**\\n* Adding a **Dropout** layer\\n\\nAnd tune their strength.\\n\\n```python\\nimport keras\\nimport keras_tuner as kt\\n\\ndef build_model(hp: kt.HyperParameters):\\n    keras.utils.set_random_seed(42)\\n\\n    units_1 = hp.Choice(\\'units_1\\', [64, 100, 128])\\n    units_2 = hp.Choice(\\'units_2\\', [64, 100, 128])\\n    lr      = hp.Choice(\\'learning_rate\\', [0.001, 0.005, 0.01])\\n\\n    # New: regularization hyperparams\\n    l2_factor = hp.Choice(\\'l2_factor\\', [0.0, 1e-4, 1e-3])\\n    dropout_rate = hp.Choice(\\'dropout_rate\\', [0.0, 0.1, 0.2])\\n\\n    reg = keras.regularizers.l2(l2_factor) if l2_factor > 0 else None\\n\\n    model = keras.Sequential(name=\"Model_A\")\\n    model.add(keras.layers.Input(shape=(11,)))\\n    model.add(keras.layers.Dense(units_1, activation=\\'relu\\',\\n                                 kernel_regularizer=reg))\\n    model.add(keras.layers.Dense(units_2, activation=\\'relu\\',\\n                                 kernel_regularizer=reg))\\n    # Optional dropout layer\\n    if dropout_rate > 0:\\n        model.add(keras.layers.Dropout(dropout_rate))\\n\\n    model.add(keras.layers.Dense(1))\\n\\n    model.compile(\\n        loss=\"mae\",\\n        optimizer=keras.optimizers.Adam(learning_rate=lr),\\n        metrics=[\"mae\", \"mse\"]\\n    )\\n    return model\\n```\\n\\nThen rerun your `GridSearch` (or better: switch to `RandomSearch` or `BayesianOptimization` so the search space can be larger):\\n\\n```python\\ntuner = kt.RandomSearch(\\n    hypermodel=build_model,\\n    objective=\"val_mae\",\\n    max_trials=30,\\n    overwrite=True,\\n    directory=\"kt_dir\",\\n    project_name=\"model_a_reg\"\\n)\\n\\ntuner.search(\\n    X_train_normal, y_train,\\n    validation_data=(X_test_normal, y_test),\\n    epochs=150,\\n    callbacks=callbacks,\\n    verbose=1\\n)\\n```\\n\\n---\\n\\n## 3. Tune batch size & number of layers\\n\\nTwo more impactful knobs:\\n\\n* **batch_size** (small batches can help generalization sometimes)\\n* **depth** (1, 2, or 3 hidden layers)\\n\\n### Example: tuning batch size\\n\\n```python\\nbatch_size = hp.Choice(\"batch_size\", [16, 32, 64, 128])\\n...\\n# in tuner.search:\\ntuner.search(\\n    X_train_normal,\\n    y_train,\\n    validation_data=(X_test_normal, y_test),\\n    epochs=150,\\n    batch_size=best_hp.get(\"batch_size\"),   # if you add it\\n    callbacks=callbacks,\\n    verbose=1\\n)\\n```\\n\\nBetter pattern: put `batch_size` also in `search` as:\\n\\n```python\\ntuner.search(\\n    X_train_normal,\\n    y_train,\\n    validation_data=(X_test_normal, y_test),\\n    epochs=150,\\n    callbacks=callbacks,\\n    verbose=1,\\n    batch_size=hp.Choice(\"batch_size\", [32, 64, 128])  # in a custom run_trial\\n)\\n```\\n\\nBut the simple way is: try a few batch sizes manually once you have a good model.\\n\\n### Example: tuning number of hidden layers\\n\\nYou can optionally add a 3rd dense layer only in some trials:\\n\\n```python\\ndef build_model(hp):\\n    keras.utils.set_random_seed(42)\\n\\n    lr = hp.Choice(\"learning_rate\", [0.001, 0.005, 0.01])\\n    num_hidden = hp.Choice(\"num_hidden\", [1, 2, 3])\\n\\n    model = keras.Sequential(name=\"Model_A\")\\n    model.add(keras.layers.Input(shape=(11,)))\\n\\n    units = hp.Choice(\"units\", [64, 100, 128])\\n\\n    for i in range(num_hidden):\\n        model.add(keras.layers.Dense(units, activation=\"relu\"))\\n\\n    model.add(keras.layers.Dense(1))\\n\\n    model.compile(\\n        loss=\"mae\",\\n        optimizer=keras.optimizers.Adam(learning_rate=lr),\\n        metrics=[\"mae\", \"mse\"],\\n    )\\n    return model\\n```\\n\\n---\\n\\n## 4. Improve input / target side (often bigger gains)\\n\\nSometimes the **biggest MAE improvement** comes from data, not layers:\\n\\n1. **Check scaling of targets (`y`)**\\n\\n   * If `y` has a long tail, try a **log transform**: `y_log = np.log1p(y)`\\n   * Train the model on `y_log`, and when predicting, invert with `np.expm1(pred)`.\\n\\n2. **Handle outliers**\\n\\n   * Clip extreme values of target or features.\\n   * Or train with a robust loss (e.g., Huber, which you already played with).\\n\\n3. **Feature engineering**\\n\\n   * Add interactions: `x1 * x2`, ratios, or bucketed versions of continuous features.\\n   * If there are categorical variables, use proper one-hot or embeddings instead of arbitrary numeric codes.\\n\\n4. **Cross-validation**\\n\\n   * Instead of a single train/val split, use **KFold** and average MAE.\\n   * This gives more stable hyperparameter selection and can reveal overfitting to a specific split.\\n\\n---\\n\\n## 5. Quick checklist â€“ what Iâ€™d do in your notebook\\n\\nIf you want a practical order:\\n\\n1. âœ… **Restart kernel** and use only `keras` + `keras_tuner` (no `tf.keras` models/callbacks).\\n2. âœ… Keep your current best hyperparams and:\\n\\n   * Recompile with `lr * 0.1`\\n   * Fine-tune 30â€“50 more epochs with callbacks.\\n3. âœ… Extend tuner search:\\n\\n   * Add **L2 + Dropout** hyperparams.\\n   * Maybe allow `num_hidden` âˆˆ {1, 2, 3}.\\n   * Switch to `RandomSearch` with ~30 trials.\\n4. âœ… Examine distribution of `y_train`:\\n\\n   * If skewed â†’ try `log1p` target.\\n5. âœ… If MAE still doesnâ€™t move much, weâ€™re probably close to the **information limit of your data** (noise level, missing features, etc.).\\n\\nIf you paste your **best_model.evaluate output** and a short description of what the target is (range, approx noise), I can suggest very specific next tweaks.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Nice, youâ€™ve now got a best model from Keras Tuner ğŸ¯\n",
    "From here there are **two big levers**:\n",
    "\n",
    "1. **Make the model itself better** (architecture, regularization, hyperparams)\n",
    "2. **Make the *data & training* setup better** (features, targets, training schedule)\n",
    "\n",
    "Iâ€™ll give you concrete things you can do *right now* with code.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Fine-tune your current best model\n",
    "\n",
    "You already have `best_model` and `best_hp`. Easiest improvement:\n",
    "**keep training the same model with a smaller learning rate.**\n",
    "\n",
    "```python\n",
    "# Take the tuned model\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "# Optionally re-train from scratch with tuned hp\n",
    "history = best_model.fit(\n",
    "    X_train_normal,\n",
    "    y_train,\n",
    "    validation_data=(X_test_normal, y_test),\n",
    "    epochs=100,\n",
    "    callbacks=callbacks,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Now fine-tune with smaller lr\n",
    "import keras\n",
    "\n",
    "old_lr = best_hp.get(\"learning_rate\")\n",
    "fine_tune_lr = old_lr * 0.1\n",
    "\n",
    "best_model.compile(\n",
    "    loss=\"mae\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "    metrics=[\"mae\", \"mse\"]\n",
    ")\n",
    "\n",
    "history_ft = best_model.fit(\n",
    "    X_train_normal,\n",
    "    y_train,\n",
    "    validation_data=(X_test_normal, y_test),\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "best_model.evaluate(X_test_normal, y_test)\n",
    "```\n",
    "\n",
    "This alone can squeeze a bit more performance by â€œpolishingâ€ weights.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Add regularization (dropout / L2) and tune it\n",
    "\n",
    "Right now your model is:\n",
    "\n",
    "* Dense â†’ Dense â†’ Dense(1)\n",
    "\n",
    "You can improve **generalization** by:\n",
    "\n",
    "* Adding **L2 weight decay**\n",
    "* Adding a **Dropout** layer\n",
    "\n",
    "And tune their strength.\n",
    "\n",
    "```python\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp: kt.HyperParameters):\n",
    "    keras.utils.set_random_seed(42)\n",
    "\n",
    "    units_1 = hp.Choice('units_1', [64, 100, 128])\n",
    "    units_2 = hp.Choice('units_2', [64, 100, 128])\n",
    "    lr      = hp.Choice('learning_rate', [0.001, 0.005, 0.01])\n",
    "\n",
    "    # New: regularization hyperparams\n",
    "    l2_factor = hp.Choice('l2_factor', [0.0, 1e-4, 1e-3])\n",
    "    dropout_rate = hp.Choice('dropout_rate', [0.0, 0.1, 0.2])\n",
    "\n",
    "    reg = keras.regularizers.l2(l2_factor) if l2_factor > 0 else None\n",
    "\n",
    "    model = keras.Sequential(name=\"Model_A\")\n",
    "    model.add(keras.layers.Input(shape=(11,)))\n",
    "    model.add(keras.layers.Dense(units_1, activation='relu',\n",
    "                                 kernel_regularizer=reg))\n",
    "    model.add(keras.layers.Dense(units_2, activation='relu',\n",
    "                                 kernel_regularizer=reg))\n",
    "    # Optional dropout layer\n",
    "    if dropout_rate > 0:\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mae\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        metrics=[\"mae\", \"mse\"]\n",
    "    )\n",
    "    return model\n",
    "```\n",
    "\n",
    "Then rerun your `GridSearch` (or better: switch to `RandomSearch` or `BayesianOptimization` so the search space can be larger):\n",
    "\n",
    "```python\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_mae\",\n",
    "    max_trials=30,\n",
    "    overwrite=True,\n",
    "    directory=\"kt_dir\",\n",
    "    project_name=\"model_a_reg\"\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train_normal, y_train,\n",
    "    validation_data=(X_test_normal, y_test),\n",
    "    epochs=150,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Tune batch size & number of layers\n",
    "\n",
    "Two more impactful knobs:\n",
    "\n",
    "* **batch_size** (small batches can help generalization sometimes)\n",
    "* **depth** (1, 2, or 3 hidden layers)\n",
    "\n",
    "### Example: tuning batch size\n",
    "\n",
    "```python\n",
    "batch_size = hp.Choice(\"batch_size\", [16, 32, 64, 128])\n",
    "...\n",
    "# in tuner.search:\n",
    "tuner.search(\n",
    "    X_train_normal,\n",
    "    y_train,\n",
    "    validation_data=(X_test_normal, y_test),\n",
    "    epochs=150,\n",
    "    batch_size=best_hp.get(\"batch_size\"),   # if you add it\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "```\n",
    "\n",
    "Better pattern: put `batch_size` also in `search` as:\n",
    "\n",
    "```python\n",
    "tuner.search(\n",
    "    X_train_normal,\n",
    "    y_train,\n",
    "    validation_data=(X_test_normal, y_test),\n",
    "    epochs=150,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    batch_size=hp.Choice(\"batch_size\", [32, 64, 128])  # in a custom run_trial\n",
    ")\n",
    "```\n",
    "\n",
    "But the simple way is: try a few batch sizes manually once you have a good model.\n",
    "\n",
    "### Example: tuning number of hidden layers\n",
    "\n",
    "You can optionally add a 3rd dense layer only in some trials:\n",
    "\n",
    "```python\n",
    "def build_model(hp):\n",
    "    keras.utils.set_random_seed(42)\n",
    "\n",
    "    lr = hp.Choice(\"learning_rate\", [0.001, 0.005, 0.01])\n",
    "    num_hidden = hp.Choice(\"num_hidden\", [1, 2, 3])\n",
    "\n",
    "    model = keras.Sequential(name=\"Model_A\")\n",
    "    model.add(keras.layers.Input(shape=(11,)))\n",
    "\n",
    "    units = hp.Choice(\"units\", [64, 100, 128])\n",
    "\n",
    "    for i in range(num_hidden):\n",
    "        model.add(keras.layers.Dense(units, activation=\"relu\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mae\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        metrics=[\"mae\", \"mse\"],\n",
    "    )\n",
    "    return model\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Improve input / target side (often bigger gains)\n",
    "\n",
    "Sometimes the **biggest MAE improvement** comes from data, not layers:\n",
    "\n",
    "1. **Check scaling of targets (`y`)**\n",
    "\n",
    "   * If `y` has a long tail, try a **log transform**: `y_log = np.log1p(y)`\n",
    "   * Train the model on `y_log`, and when predicting, invert with `np.expm1(pred)`.\n",
    "\n",
    "2. **Handle outliers**\n",
    "\n",
    "   * Clip extreme values of target or features.\n",
    "   * Or train with a robust loss (e.g., Huber, which you already played with).\n",
    "\n",
    "3. **Feature engineering**\n",
    "\n",
    "   * Add interactions: `x1 * x2`, ratios, or bucketed versions of continuous features.\n",
    "   * If there are categorical variables, use proper one-hot or embeddings instead of arbitrary numeric codes.\n",
    "\n",
    "4. **Cross-validation**\n",
    "\n",
    "   * Instead of a single train/val split, use **KFold** and average MAE.\n",
    "   * This gives more stable hyperparameter selection and can reveal overfitting to a specific split.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Quick checklist â€“ what Iâ€™d do in your notebook\n",
    "\n",
    "If you want a practical order:\n",
    "\n",
    "1. âœ… **Restart kernel** and use only `keras` + `keras_tuner` (no `tf.keras` models/callbacks).\n",
    "2. âœ… Keep your current best hyperparams and:\n",
    "\n",
    "   * Recompile with `lr * 0.1`\n",
    "   * Fine-tune 30â€“50 more epochs with callbacks.\n",
    "3. âœ… Extend tuner search:\n",
    "\n",
    "   * Add **L2 + Dropout** hyperparams.\n",
    "   * Maybe allow `num_hidden` âˆˆ {1, 2, 3}.\n",
    "   * Switch to `RandomSearch` with ~30 trials.\n",
    "4. âœ… Examine distribution of `y_train`:\n",
    "\n",
    "   * If skewed â†’ try `log1p` target.\n",
    "5. âœ… If MAE still doesnâ€™t move much, weâ€™re probably close to the **information limit of your data** (noise level, missing features, etc.).\n",
    "\n",
    "If you paste your **best_model.evaluate output** and a short description of what the target is (range, approx noise), I can suggest very specific next tweaks.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90e0777-2ee2-46ec-97e6-d48426440e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2. Use a smarter tuner than GridSearch\\n\\nGridSearch explodes combinatorially and often wastes trials. For neural nets, RandomSearch or BayesianOptimization usually find better configs faster.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. Use a smarter tuner than GridSearch\n",
    "\n",
    "GridSearch explodes combinatorially and often wastes trials. For neural nets, RandomSearch or BayesianOptimization usually find better configs faster.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6959a70d-f3cd-4ca7-b087-ad0e459f3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.12/dist-packages (1.4.8)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.62.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (4.25.3)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from absl-py->keras->keras-tuner) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098fcfb0-7501-4849-80ff-52c9fe103aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import keras \n",
    "import keras_tuner as kt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54953c9-6a8a-495c-84a6-c939d9cc1e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data \n",
    "insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/refs/heads/master/insurance.csv')\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade82f77-4f2a-4688-9893-111ff330ac3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19055236-b803-477c-a10b-c213519e3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y and train test splits \n",
    "\n",
    "X = insurance.drop('charges', axis=1)\n",
    "y = insurance.charges\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8872b912-9ea1-4a8b-9ff7-9f1937dcaaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "         1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.63043478, 0.22491256, 0.        , 1.        , 0.        ,\n",
       "         1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.58695652, 0.24791499, 0.4       , 1.        , 0.        ,\n",
       "         1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.39130435, 0.37826204, 0.        , 1.        , 0.        ,\n",
       "         1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        ]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess Data\n",
    "\n",
    "# 1. Create transformerabs\n",
    "\n",
    "col_transformer = make_column_transformer(\n",
    "    (MinMaxScaler(), ['age', 'bmi', 'children']),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), ['sex', 'smoker', 'region'])\n",
    ")\n",
    "\n",
    "# 2. Fit training data \n",
    "col_transformer.fit(X_train) \n",
    "\n",
    "# 3. Transform train and test data \n",
    "X_train_normal = col_transformer.transform(X_train)\n",
    "X_test_normal = col_transformer.transform(X_test) \n",
    "\n",
    "X_train_normal[:2], X_test_normal[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20bad2f0-414c-48f8-9eb3-07590c573f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create build_model function\n",
    "\n",
    "def build_model(hp: kt.HyperParameters):\n",
    "\n",
    "    # 1. Set keras seed\n",
    "    keras.utils.set_random_seed(42)\n",
    "\n",
    "    # 2. Create options \n",
    "    units = hp.Choice('units_1', [100, 128, 256])\n",
    "    lr = hp.Choice('learning_rate', [0.05, 0.01])\n",
    "    num_hidden = hp.Choice('num_hidden', [2, 3])\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(11,)))\n",
    "\n",
    "    for unit in range(num_hidden):\n",
    "        model.add(keras.layers.Dense(units, activation='relu'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='mae',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr), \n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13673194-77cf-4cd6-ac60-7f049e724e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=5,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "        start_from_epoch=0\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=5,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False,\n",
    "        start_from_epoch=0,\n",
    "        min_lr=1e-5\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05357da3-d033-44fd-95e7-a1c8d454f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.GridSearch(\n",
    "    hypermodel=build_model, \n",
    "    objective='val_mae', \n",
    "    overwrite=True, \n",
    "    seed=42, \n",
    "    directory='kt_dir', \n",
    "    project_name='model_a_grid_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f907fec3-1df2-4167-bdeb-825abd438809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 00m 07s]\n",
      "val_mae: 2674.27294921875\n",
      "\n",
      "Best val_mae So Far: 2619.53466796875\n",
      "Total elapsed time: 00h 01m 41s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    X_train_normal, \n",
    "    y_train, \n",
    "    validation_data=(X_test_normal, y_test),\n",
    "    epochs=150, \n",
    "    callbacks=callbacks, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c644804-6f76-419e-bca8-1ef923924425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Units :  3\n",
      "Best LR :  0.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m1,536\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m16,512\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m16,512\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,560</span> (135.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,560\u001b[0m (135.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,560</span> (135.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,560\u001b[0m (135.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11301.3984 - mae: 11301.3984 - mse: 256620784.0000 - val_loss: 7112.2612 - val_mae: 7112.2612 - val_mse: 114595872.0000 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5722.5522 - mae: 5722.5522 - mse: 86189256.0000 - val_loss: 3719.9709 - val_mae: 3719.9709 - val_mse: 59662488.0000 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4132.0952 - mae: 4132.0952 - mse: 66720124.0000 - val_loss: 3594.5996 - val_mae: 3594.5996 - val_mse: 60745032.0000 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4039.5518 - mae: 4039.5518 - mse: 66747432.0000 - val_loss: 3634.3088 - val_mae: 3634.3088 - val_mse: 56530316.0000 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4001.4922 - mae: 4001.4922 - mse: 63362716.0000 - val_loss: 3598.3828 - val_mae: 3598.3828 - val_mse: 57785464.0000 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3945.7405 - mae: 3945.7405 - mse: 62848164.0000 - val_loss: 3606.5564 - val_mae: 3606.5564 - val_mse: 57431188.0000 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3936.2998 - mae: 3936.2998 - mse: 61551188.0000 - val_loss: 3563.2788 - val_mae: 3563.2788 - val_mse: 58455752.0000 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3844.6853 - mae: 3844.6853 - mse: 59711188.0000 - val_loss: 3569.1726 - val_mae: 3569.1726 - val_mse: 54021012.0000 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3732.9338 - mae: 3732.9338 - mse: 56098764.0000 - val_loss: 3548.5317 - val_mae: 3548.5317 - val_mse: 53553304.0000 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3563.5002 - mae: 3563.5002 - mse: 53990420.0000 - val_loss: 3361.4060 - val_mae: 3361.4060 - val_mse: 50894024.0000 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3361.4937 - mae: 3361.4937 - mse: 51031348.0000 - val_loss: 3269.5889 - val_mae: 3269.5889 - val_mse: 49792580.0000 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3205.9834 - mae: 3205.9834 - mse: 49392628.0000 - val_loss: 3125.5071 - val_mae: 3125.5071 - val_mse: 47691900.0000 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3161.9109 - mae: 3161.9109 - mse: 47963696.0000 - val_loss: 3454.7976 - val_mae: 3454.7976 - val_mse: 44979680.0000 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3384.3274 - mae: 3384.3274 - mse: 46768872.0000 - val_loss: 2916.8735 - val_mae: 2916.8735 - val_mse: 41484804.0000 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3029.9185 - mae: 3029.9185 - mse: 44043232.0000 - val_loss: 2619.5347 - val_mae: 2619.5347 - val_mse: 39918020.0000 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2923.1252 - mae: 2923.1252 - mse: 43335644.0000 - val_loss: 2716.8972 - val_mae: 2716.8972 - val_mse: 40424196.0000 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2911.6699 - mae: 2911.6699 - mse: 43320052.0000 - val_loss: 3573.3779 - val_mae: 3573.3779 - val_mse: 41889956.0000 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3395.3010 - mae: 3395.3010 - mse: 45504780.0000 - val_loss: 2733.7229 - val_mae: 2733.7229 - val_mse: 39137560.0000 - learning_rate: 0.0500\n",
      "Epoch 19/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2899.6965 - mae: 2899.6965 - mse: 42699644.0000 - val_loss: 2639.9714 - val_mae: 2639.9714 - val_mse: 40229524.0000 - learning_rate: 0.0500\n",
      "Epoch 20/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2810.9177 - mae: 2810.9177 - mse: 42975872.0000 - val_loss: 2683.0696 - val_mae: 2683.0696 - val_mse: 41364032.0000 - learning_rate: 0.0500\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Units : \", best_hp.get('num_hidden'))\n",
    "print('Best LR : ', best_hp.get('learning_rate'))\n",
    "\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "best_model.summary()\n",
    "\n",
    "history = best_model.fit(\n",
    "    X_train_normal,\n",
    "    y_train,\n",
    "    validation_data=(X_test_normal, y_test), \n",
    "    epochs=150, \n",
    "    callbacks=callbacks, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d70ca0c1-9dea-4abb-900a-de5ffe95250f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF+PyTorch (Docker)",
   "language": "python",
   "name": "tf-pytorch-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
