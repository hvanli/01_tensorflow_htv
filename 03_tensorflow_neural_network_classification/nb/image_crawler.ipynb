{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b08032b-d008-4c3c-abf7-e53437fb8b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting icrawler\n",
      "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from icrawler) (4.13.3)\n",
      "Collecting bs4 (from icrawler)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting lxml (from icrawler)\n",
      "  Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from icrawler) (12.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from icrawler) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from icrawler) (2.32.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from icrawler) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->icrawler) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->icrawler) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (2024.12.14)\n",
      "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml, bs4, icrawler\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [icrawler]\n",
      "\u001b[1A\u001b[2KSuccessfully installed bs4-0.0.2 icrawler-0.6.10 lxml-6.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install icrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b821a12-1f1d-4eac-9cc2-09ea17670df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "from icrawler.builtin import BingImageCrawler\n",
    "\n",
    "TF_SUPPORTED_FORMATS = {\"JPEG\", \"PNG\", \"GIF\", \"BMP\"}\n",
    "\n",
    "def _count_supported_images(folder: Path) -> int:\n",
    "    count = 0\n",
    "    for p in folder.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        try:\n",
    "            with Image.open(p) as img:\n",
    "                img.verify()\n",
    "                fmt = img.format\n",
    "            if fmt in TF_SUPPORTED_FORMATS:\n",
    "                count += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "    return count\n",
    "\n",
    "def _clean_folder_tf_supported_and_min_size(folder: Path, min_w=224, min_h=224) -> tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Deletes:\n",
    "      - non-images/corrupted images\n",
    "      - formats not supported by TF (JPEG/PNG/GIF/BMP)\n",
    "      - images smaller than min_w x min_h\n",
    "\n",
    "    Returns: (checked, removed, kept)\n",
    "    \"\"\"\n",
    "    checked = removed = kept = 0\n",
    "\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            path = Path(root) / f\n",
    "            checked += 1\n",
    "            try:\n",
    "                with Image.open(path) as img:\n",
    "                    img.verify()\n",
    "                    fmt = img.format\n",
    "\n",
    "                if fmt not in TF_SUPPORTED_FORMATS:\n",
    "                    path.unlink(missing_ok=True)\n",
    "                    removed += 1\n",
    "                    continue\n",
    "\n",
    "                # Re-open after verify() to read size\n",
    "                with Image.open(path) as img2:\n",
    "                    w, h = img2.size\n",
    "\n",
    "                if w < min_w or h < min_h:\n",
    "                    path.unlink(missing_ok=True)\n",
    "                    removed += 1\n",
    "                    continue\n",
    "\n",
    "                kept += 1\n",
    "            except Exception:\n",
    "                # corrupted/unreadable/not an image\n",
    "                path.unlink(missing_ok=True)\n",
    "                removed += 1\n",
    "\n",
    "    return checked, removed, kept\n",
    "\n",
    "def download_images_for_class_tf_ready(\n",
    "    class_name: str,\n",
    "    n_images: int,\n",
    "    target_root: str,\n",
    "    min_size=(224, 224),\n",
    "    bing_filters=None,\n",
    "    buffer_factor: float = 2.0,\n",
    "    max_rounds: int = 3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Downloads images for `class_name` into target_root/class_name\n",
    "    then cleans the folder to keep only TF-supported formats and min resolution.\n",
    "\n",
    "    Notes:\n",
    "      - Because search results include webp/avif/svg/corrupt files, we download extra\n",
    "        (buffer_factor) and then delete the bad ones.\n",
    "      - We optionally retry a few rounds until we have >= n_images valid images.\n",
    "    \"\"\"\n",
    "    save_dir = Path(target_root) / class_name\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    min_w, min_h = min_size\n",
    "    filters = bing_filters or {\"type\": \"photo\", \"size\": \"large\"}  # size is a hint, not a guarantee\n",
    "\n",
    "    for round_idx in range(1, max_rounds + 1):\n",
    "        current_valid = _count_supported_images(save_dir)\n",
    "        if current_valid >= n_images:\n",
    "            break\n",
    "\n",
    "        need = n_images - current_valid\n",
    "        to_download = max(int(need * buffer_factor), need)\n",
    "\n",
    "        crawler = BingImageCrawler(storage={\"root_dir\": str(save_dir)})\n",
    "        crawler.crawl(keyword=class_name, max_num=to_download, filters=filters)\n",
    "\n",
    "        checked, removed, kept = _clean_folder_tf_supported_and_min_size(save_dir, min_w, min_h)\n",
    "        current_valid = _count_supported_images(save_dir)\n",
    "\n",
    "        print(\n",
    "            f\"[{class_name}] round {round_idx}/{max_rounds} | \"\n",
    "            f\"downloaded≈{to_download} | checked={checked}, removed={removed}, kept={kept} | \"\n",
    "            f\"valid_now={current_valid}/{n_images}\"\n",
    "        )\n",
    "\n",
    "    final_valid = _count_supported_images(save_dir)\n",
    "    if final_valid < n_images:\n",
    "        print(f\"Warning: only {final_valid} TF-ready images found for '{class_name}'. \"\n",
    "              f\"Try increasing max_rounds/buffer_factor or tweak search term/filters.\")\n",
    "    else:\n",
    "        print(f\"Done: {final_valid} TF-ready images for '{class_name}' in {save_dir}\")\n",
    "\n",
    "    return str(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080b7f2e-35b3-44c9-a919-62e32a3e11fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pizza] round 1/3 | downloaded≈200 | checked=164, removed=2, kept=162 | valid_now=162/100\n",
      "Done: 162 TF-ready images for 'pizza' in ../data/pizza_steak/valid/pizza\n",
      "[steak] round 1/3 | downloaded≈200 | checked=179, removed=0, kept=179 | valid_now=179/100\n",
      "Done: 179 TF-ready images for 'steak' in ../data/pizza_steak/valid/steak\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/pizza_steak/valid/steak'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_images_for_class_tf_ready(\n",
    "    class_name=\"pizza\",\n",
    "    n_images=100,\n",
    "    target_root=\"../data/pizza_steak/valid\",\n",
    "    min_size=(224, 224)\n",
    ")\n",
    "\n",
    "download_images_for_class_tf_ready(\n",
    "    class_name=\"steak\",\n",
    "    n_images=100,\n",
    "    target_root=\"../data/pizza_steak/valid\",\n",
    "    min_size=(224, 224)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF+PyTorch (Docker)",
   "language": "python",
   "name": "tf-pytorch-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
